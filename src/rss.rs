// RSSå¤„ç†æ¨¡å—

use crate::models::Article;
use chrono::{DateTime, Utc};
use flate2::read::GzDecoder;
use headless_chrome::{Browser, LaunchOptionsBuilder};
use html2text::from_read;
use reqwest::Url;
use roxmltree::Document;
use rss::{Channel, Item};
use std::collections::HashMap;
use std::ffi::OsStr;
use std::io::Cursor;
use std::sync::Arc;
use std::time::Instant;
use thiserror::Error;
use tokio::sync::Mutex;
use tokio::time::sleep;

// å®šä¹‰ç±»å‹åˆ«åç®€åŒ–å¤æ‚ç±»å‹
type ArticleCache = Arc<Mutex<HashMap<String, (Instant, Vec<Article>)>>>;

/// RSSé”™è¯¯ç±»å‹
#[derive(Error, Debug)]
pub enum RssError {
    #[error("HTTPè¯·æ±‚é”™è¯¯: {0}")]
    HttpError(#[from] reqwest::Error),

    #[error("RSSè§£æé”™è¯¯: {0}")]
    ParseError(#[from] rss::Error),

    #[error("æ—¶é—´è§£æé”™è¯¯: {0}")]
    TimeError(#[from] chrono::ParseError),

    #[error("ç½‘ç»œé”™è¯¯: {0}")]
    NetworkError(String),

    #[error("XMLè§£æé”™è¯¯: {0}")]
    XmlError(String),

    #[error("Atomè§£æé”™è¯¯")]
    AtomParseError,

    #[error("æœªçŸ¥é”™è¯¯")]
    Unknown,
}

/// RSSè·å–å™¨
pub struct RssFetcher {
    client: reqwest::Client,

    /// ç”¨æˆ·ä»£ç†
    user_agent: String,

    /// å†…å­˜ç¼“å­˜
    cache: ArticleCache,

    cache_ttl: u64,
}

impl RssFetcher {
    pub fn new(user_agent: String) -> Self {
        let client = reqwest::Client::builder()
            .user_agent(&user_agent)
            .timeout(std::time::Duration::from_secs(30))
            .connect_timeout(std::time::Duration::from_secs(10))
            .tcp_keepalive(Some(std::time::Duration::from_secs(30)))
            .build()
            .expect("Failed to create HTTP client");

        Self {
            client,
            user_agent,
            cache: Arc::new(Mutex::new(HashMap::new())),
            cache_ttl: 300, // æ¦›æ¨¿î…»5é’å—›æŒ“ç¼‚æ’³ç“¨
        }
    }

    /// è®¾ç½®ç¼“å­˜è¿‡æœŸæ—¶é—´
    #[allow(unused)]
    pub fn set_cache_ttl(&mut self, ttl_seconds: u64) {
        self.cache_ttl = ttl_seconds;
    }

    /// æ¸…é™¤ç¼“å­˜
    #[allow(unused)]
    pub async fn clear_cache(&self) {
        let mut cache = self.cache.lock().await;
        cache.clear();
    }

    /// ä¸ºexample://åè®®ç”Ÿæˆç¤ºä¾‹æ–‡ç« 
    async fn generate_example_articles(&self, url: &str) -> Vec<Article> {
        let mut articles = Vec::new();

        // æ ¹æ®URLç”Ÿæˆä¸åŒå†…å®¹çš„ç¤ºä¾‹æ–‡ç« 
        let title = match url {
            "example://welcome" => "æ¬¢è¿ä½¿ç”¨ Rust RSS é˜…è¯»å™¨",
            _ => "ç¤ºä¾‹æ–‡ç« æ ‡é¢˜",
        };

        // åˆ›å»ºç¤ºä¾‹æ–‡ç« 
        let example_article = Article {
            id: 0, // å°†åœ¨å­˜å‚¨æ—¶åˆ†é…ID
            feed_id: 0, // å°†åœ¨å­˜å‚¨æ—¶åˆ†é…feed_id
            title: title.to_string(),
            link: url.to_string(),
            summary: "è¿™æ˜¯ä¸€ç¯‡ç¤ºä¾‹æ–‡ç« ï¼Œç”¨äºæµ‹è¯•ç›®çš„ã€‚".to_string(),
            content: "<p>è¿™æ˜¯ç¤ºä¾‹æ–‡ç« çš„è¯¦ç»†å†…å®¹ã€‚</p><p>Rust RSS é˜…è¯»å™¨æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ã€è½»é‡çº§çš„RSSé˜…è¯»åº”ç”¨ã€‚</p>".to_string(),
            author: "Rust RSS Reader Team".to_string(),
            pub_date: Utc::now(),
            is_read: false,
            is_starred: false,
            guid: format!("{}-{}", url, Utc::now().timestamp()),
            source: url.to_string(), // æ·»åŠ sourceå­—æ®µ
        };

        articles.push(example_article);
        articles
    }



    /// å•æ¬¡è·å–ç½‘é¡µå†…å®¹
    #[allow(unused)]
    async fn fetch_web_content_once(&self, url: &str) -> Result<String, RssError> {
        // æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆ
        if !url.starts_with("http://") && !url.starts_with("https://") {
            return Err(RssError::NetworkError("Invalid URL format".to_string()));
        }

        log::debug!("Fetching web content from: {}", url);

        // å‘é€HTTPè¯·æ±‚ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è¡Œä¸º
        let response = self.client.get(url)
            .header("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
            .header("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7")
            .header("Accept-Encoding", "identity") // æ˜ç¡®è¦æ±‚ä¸å‹ç¼©ï¼Œé¿å…gzipè§£å‹é—®é¢˜
            .header("Accept-Language", "zh-CN,zh;q=0.9,en;q=0.8")
            .header("Referer", "https://www.google.com/")
            .header("DNT", "1")
            .header("Upgrade-Insecure-Requests", "1")
            .timeout(std::time::Duration::from_secs(15))
            .send()
            .await?;

        // æ£€æŸ¥å“åº”çŠ¶æ€
        let status = response.status();
        if !status.is_success() {
            // åªè¿”å›çŠ¶æ€ç å’Œç®€çŸ­æè¿°ï¼Œä¸è¿”å›å®Œæ•´çš„é”™è¯¯å“åº”å†…å®¹
            // å¯¹äº403é”™è¯¯ï¼Œç‰¹åˆ«å¤„ç†ï¼Œåªæ˜¾ç¤ºçŠ¶æ€ç å’Œç®€çŸ­æè¿°
            let error_msg = match status.as_u16() {
                403 => "HTTP 403 Forbidden - æœåŠ¡å™¨æ‹’ç»è®¿é—®è¯¥ç½‘é¡µ".to_string(),
                404 => "HTTP 404 Not Found - ç½‘é¡µä¸å­˜åœ¨".to_string(),
                500 => "HTTP 500 Internal Server Error - æœåŠ¡å™¨å†…éƒ¨é”™è¯¯".to_string(),
                503 => "HTTP 503 Service Unavailable - æœåŠ¡å™¨æš‚æ—¶ä¸å¯ç”¨".to_string(),
                _ => format!("HTTP {} - è¯·æ±‚å¤±è´¥", status),
            };
            return Err(RssError::NetworkError(error_msg));
        }

        // è·å–å†…å®¹
        let content = response.text().await?;
        Ok(content)
    }

    /// è·å–å¹¶è§£æRSSæºï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
    pub async fn fetch_feed(&self, url: &str) -> Result<Vec<Article>, RssError> {
        if let Some(articles) = self.get_from_cache(url).await {
            log::info!("Returning cached articles for {}", url);
            return Ok(articles);
        }

        log::info!("Fetching feed: {}", url);

        // é‡è¯•æœºåˆ¶
        let max_retries = 3;
        let mut last_error: Option<RssError> = None;

        for attempt in 0..max_retries {
            match self.fetch_feed_once(url).await {
                Ok(articles) => {
                    // ç¼“å­˜ç»“æœï¼ˆç›´æ¥ä¼ é€’ï¼Œé¿å…cloneï¼‰
                    self.add_to_cache(url, articles.clone()).await;
                    log::info!(
                        "Successfully fetched {} articles from {}",
                        articles.len(),
                        url
                    );
                    return Ok(articles);
                }
                Err(e) => {
                    last_error = Some(e);
                    log::warn!(
                        "Attempt {}/{} failed for {}: {:?}",
                        attempt + 1,
                        max_retries,
                        url,
                        last_error
                    );

                    // æŒ‡æ•°é€€é¿é‡è¯•
                    if attempt < max_retries - 1 {
                        let delay_ms = 200 * (2_u64.pow(attempt as u32));
                        log::info!("Retrying after {}ms...", delay_ms);
                        sleep(tokio::time::Duration::from_millis(delay_ms)).await;
                    }
                }
            }
        }

        // æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        Err(last_error.unwrap_or(RssError::Unknown))
    }

    async fn fetch_feed_once(&self, url: &str) -> Result<Vec<Article>, RssError> {
        // æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆ
        if !url.starts_with("http://") && !url.starts_with("https://") {
            // ç‰¹æ®Šå¤„ç†example://åè®®ï¼Œè¿”å›ç¤ºä¾‹æ–‡ç« 
            if url.starts_with("example://") {
                log::info!("Handling example protocol URL: {}", url);
                return Ok(self.generate_example_articles(url).await);
            }
            return Err(RssError::NetworkError("Invalid URL format".to_string()));
        }

        log::debug!("Fetching feed from: {}", url);

        // å‘é€HTTPè¯·æ±‚ï¼Œæ·»åŠ æ›´å¤šçš„å®¹é”™å¤„ç†
        let response = self
            .client
            .get(url)
            .header("User-Agent", &self.user_agent)
            .header(
                "Accept",
                "application/rss+xml, application/atom+xml, application/xml, text/xml, */*",
            )
            .header("Referer", url) // ç­–ç•¥1ï¼šæŒ‡å‘è‡ªå·±ï¼ˆç®€å•æœ‰æ•ˆï¼‰
            //.header("Accept-Encoding", "identity") // æ˜ç¡®è¦æ±‚ä¸å‹ç¼©ï¼Œé¿å…gzipè§£å‹é—®é¢˜
            .header("Cache-Control", "no-cache")
            .header("Accept-Language", "zh-CN,zh;q=0.9,en;q=0.8") // æ·»åŠ è¯­è¨€æ”¯æŒ
            .timeout(std::time::Duration::from_secs(15)) // å¢åŠ è¶…æ—¶æ—¶é—´
            .send()
            .await?;

        // è·å–Content-Typeå’ŒContent-Encoding
        let content_type_str = response
            .headers()
            .get("content-type")
            .and_then(|v| v.to_str().ok())
            .unwrap_or("")
            .to_string();

        let content_encoding = response
            .headers()
            .get("content-encoding")
            .and_then(|v| v.to_str().ok())
            .unwrap_or("")
            .to_lowercase();

        // å…ˆè·å–status
        let status = response.status();

        log::debug!("Content-Encoding: {} for {}", content_encoding, url);

        // å¯¹äºé”™è¯¯çŠ¶æ€ï¼Œæˆ‘ä»¬åªéœ€è¦è¯»å–æ–‡æœ¬
        if !status.is_success() {
            // å¦‚æœæ˜¯403é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨Headless Chromeè·å–
            if status.as_u16() == 403 {
                log::warn!("HTTP 403 Forbiddenï¼Œå°è¯•ä½¿ç”¨Headless Chromeè·å–RSSæº: {}", url);
                return self.fetch_feed_with_headless_chrome(url).await;
            }
            
            let error_text = response.text().await.unwrap_or_default();
            return Err(RssError::NetworkError(format!(
                "HTTP error: {} - {}",
                status,
                error_text
            )));
        }

        // å¯¹äºæˆåŠŸçŠ¶æ€ï¼Œè¯»å–å­—èŠ‚
        let body = response.bytes().await?;

        // æ·»åŠ å†…å®¹å®Œæ•´æ€§æ£€æŸ¥
        if body.is_empty() {
            log::error!("Response body is empty for URL: {}", url);
            return Err(RssError::NetworkError("æœåŠ¡å™¨è¿”å›ç©ºå†…å®¹".to_string()));
        }

        log::debug!("Content-Type: {} for {}", content_type_str, url);

        // æ·»åŠ è¯¦ç»†æ—¥å¿—ï¼Œå¸®åŠ©è°ƒè¯•
        log::debug!("Response body length: {} bytes", body.len());

        // æ‰“å°å‰200å­—èŠ‚çš„åå…­è¿›åˆ¶è¡¨ç¤ºï¼Œç”¨äºè°ƒè¯•
        let preview_size = std::cmp::min(body.len(), 200);
        log::debug!(
            "First {} bytes of response: {:?}",
            preview_size,
            &body[..preview_size]
        );

        // æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„XMLèµ·å§‹æ ‡ç­¾
        let s = String::from_utf8_lossy(&body);
        let is_valid_xml = s.trim_start().starts_with("<?xml") || s.trim_start().starts_with("<rss") || s.trim_start().starts_with("<feed");

        if !is_valid_xml {
            log::error!("Response does not contain valid XML content for URL: {}", url);
            // å°è¯•å°†å“åº”è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œä»¥ä¾¿è®°å½•
            if let Ok(text) = String::from_utf8(body.to_vec()) {
                log::error!("Invalid XML content preview: {}", text.chars().take(500).collect::<String>());
            }
            return Err(RssError::NetworkError("æœåŠ¡å™¨è¿”å›æ— æ•ˆçš„XMLå†…å®¹".to_string()));
        }

        // æ£€æŸ¥æ˜¯å¦æ˜¯HTMLé¡µé¢ï¼ˆå¯èƒ½æ˜¯é”™è¯¯é¡µé¢æˆ–é‡å®šå‘ï¼‰
        if let Ok(text) = String::from_utf8(body.to_vec()) {
            let lower_text = text.to_lowercase();
            if lower_text.contains("<!doctype html") || lower_text.contains("<html") {
                // æ£€æŸ¥æ˜¯å¦æ˜¯404é¡µé¢
                if lower_text.contains("404") || lower_text.contains("not found") {
                    return Err(RssError::NetworkError(
                        "æœåŠ¡å™¨è¿”å›404é”™è¯¯ï¼Œè¯¥RSSæºå¯èƒ½ä¸å­˜åœ¨æˆ–å·²æ›´æ”¹".to_string(),
                    ));
                }
                log::warn!("æ£€æµ‹åˆ°HTMLå†…å®¹è€ŒéRSSï¼Œå¯èƒ½æ˜¯é”™è¯¯é¡µé¢æˆ–é‡å®šå‘");

                // å°è¯•æå–å¯èƒ½çš„RSSé“¾æ¥ï¼ˆæ¯”å¦‚link rel="alternate" type="application/rss+xml"ï¼‰
                if let Some(rss_link) = self.extract_rss_link_from_html(&text) {
                    log::info!("ä»HTMLé¡µé¢ä¸­æå–åˆ°RSSé“¾æ¥: {}", rss_link);
                    // è¿”å›ç‰¹æ®Šé”™è¯¯ï¼Œæç¤ºç”¨æˆ·ä½¿ç”¨æå–åˆ°çš„RSSé“¾æ¥
                    return Err(RssError::NetworkError(format!(
                        "æ£€æµ‹åˆ°HTMLé¡µé¢ï¼Œå·²æå–RSSé“¾æ¥: {}",
                        rss_link
                    )));
                }
            }
        }

        // 1. å°è¯•ç›´æ¥è§£æ
        match Channel::read_from(&body[..]) {
            Ok(channel) => {
                log::info!("ğŸ‰ ç›´æ¥è§£ææˆåŠŸ");
                return Ok(self.parse_items_to_articles(&channel));
            }
            Err(e) => log::error!("Failed to parse RSS content directly: {:?}", e),
        }

        // 2. å°è¯•ç§»é™¤BOMï¼ˆByte Order Markï¼‰
        log::info!("å°è¯•ç§»é™¤BOMåè§£æ");
        if body.len() >= 3 && body[0] == 0xEF && body[1] == 0xBB && body[2] == 0xBF {
            // ç§»é™¤UTF-8 BOM
            let bomless = &body[3..];
            match Channel::read_from(bomless) {
                Ok(channel) => {
                    log::info!("ğŸ‰ ç§»é™¤UTF-8 BOMåè§£ææˆåŠŸ");
                    return Ok(self.parse_items_to_articles(&channel));
                }
                Err(e) => log::error!("ç§»é™¤UTF-8 BOMåè§£æå¤±è´¥: {:?}", e),
            }
        }

        // 3. å°è¯•ä½¿ç”¨UTF-8è½¬æ¢ä¸lossyå¤„ç†
        log::info!("å°è¯•UTF-8 lossyè½¬æ¢åè§£æ");
        let lossy_text = String::from_utf8_lossy(&body);
        match Channel::read_from(lossy_text.as_bytes()) {
            Ok(channel) => {
                log::info!("ğŸ‰ UTF-8 lossyè½¬æ¢åè§£ææˆåŠŸ");
                return Ok(self.parse_items_to_articles(&channel));
            }
            Err(e) => log::error!("UTF-8 lossyè½¬æ¢åè§£æå¤±è´¥: {:?}", e),
        }

        // 4. å°è¯•ä¸åŒçš„ç¼–ç ï¼ˆå¦‚GBKï¼‰
        log::info!("å°è¯•ä½¿ç”¨GBKç¼–ç è§£æ");
        let (text, _encoding, _had_errors) = encoding_rs::GBK.decode(&body);
        match Channel::read_from(text.as_bytes()) {
            Ok(channel) => {
                log::info!("ğŸ‰ GBKè§£ç åè§£ææˆåŠŸ");
                return Ok(self.parse_items_to_articles(&channel));
            }
            Err(e) => log::error!("GBKè§£ç åè§£æå¤±è´¥: {:?}", e),
        }

        // 5. å°è¯•æ›´å¤šç¼–ç 
        log::info!("å°è¯•ä½¿ç”¨UTF-16ç¼–ç è§£æ");
        if let Ok(utf16_text) = String::from_utf16(&self.try_decode_utf16(&body)) {
            match Channel::read_from(utf16_text.as_bytes()) {
                Ok(channel) => {
                    log::info!("ğŸ‰ UTF-16è§£ç åè§£ææˆåŠŸ");
                    return Ok(self.parse_items_to_articles(&channel));
                }
                Err(e) => log::error!("UTF-16è§£ç åè§£æå¤±è´¥: {:?}", e),
            }
        }

        // 6. å°è¯•ä½¿ç”¨GBKç¼–ç çš„å¦ä¸€ç§å®ç°æ–¹å¼
        log::info!("å°è¯•ä½¿ç”¨GBKç¼–ç çš„æ›¿ä»£å®ç°è§£æ");
        // å¯¼å…¥encoding_rsçš„ç¼–ç å¸¸é‡
        use encoding_rs::{GBK, EUC_KR};
        let (text, _encoding, _had_errors) = GBK.decode(&body);
        match Channel::read_from(text.as_bytes()) {
            Ok(channel) => {
                log::info!("ğŸ‰ GBKæ›¿ä»£å®ç°è§£ç åè§£ææˆåŠŸ");
                return Ok(self.parse_items_to_articles(&channel));
            }
            Err(e) => log::error!("GBKæ›¿ä»£å®ç°è§£ç åè§£æå¤±è´¥: {:?}", e),
        }
        
        // 7. å°è¯•ä½¿ç”¨EUC-KRç¼–ç ï¼ˆéŸ©æ–‡ç¼–ç ï¼‰
        log::info!("å°è¯•ä½¿ç”¨EUC-KRç¼–ç è§£æ");
        let (text, _encoding, _had_errors) = EUC_KR.decode(&body);
        let text_bytes = text.as_bytes();
        match Channel::read_from(text_bytes) {
            Ok(channel) => {
                log::info!("ğŸ‰ EUC-KRè§£ç åè§£ææˆåŠŸ");
                return Ok(self.parse_items_to_articles(&channel));
            }
            Err(e) => log::error!("EUC-KRè§£ç åè§£æå¤±è´¥: {:?}", e),
        }

        // 7. å°è¯•å¯¹æ–‡æœ¬è¿›è¡Œæ¸…ç†å’Œé¢„å¤„ç†
        log::info!("å°è¯•æ–‡æœ¬æ¸…ç†å’Œé¢„å¤„ç†åè§£æ");
        // String::from_utf8_lossyç›´æ¥è¿”å›Stringï¼Œä¸éœ€è¦ResultåŒ¹é…
        let text = String::from_utf8_lossy(&body).to_string();
        // ç§»é™¤BOMå­—ç¬¦
        let cleaned_text = text.replace("\u{FEFF}", "");
        // å°è¯•ç§»é™¤HTMLæ ‡ç­¾
        let cleaned_text = regex::Regex::new(r"<[^>]*>")
            .ok().map(|re| re.replace_all(&cleaned_text, "").to_string())
            .unwrap_or(cleaned_text);

        match Channel::read_from(cleaned_text.as_bytes()) {
            Ok(channel) => {
                log::info!("ğŸ‰ æ–‡æœ¬æ¸…ç†åè§£ææˆåŠŸ");
                return Ok(self.parse_items_to_articles(&channel));
            }
            Err(e) => log::error!("æ–‡æœ¬æ¸…ç†åè§£æå¤±è´¥: {:?}", e),
        }

        // 5. å°è¯•è§£å‹ï¼ˆå¦‚æœå“åº”å¯èƒ½è¢«å‹ç¼©ï¼‰
        log::info!("å°è¯•è§£å‹åè§£æ");
        let should_try_decompress = content_encoding.contains("gzip")
            || content_encoding.contains("br")
            || content_encoding.contains("deflate")
            || body.len() > 100; // å¦‚æœå†…å®¹è¾ƒé•¿ï¼Œä¹Ÿå°è¯•è§£å‹

        if should_try_decompress {
            log::info!("Attempting to decompress based on Content-Encoding or content length");
            if let Ok(decompressed) = self.try_decompress_gzip(&body) {
                log::info!("Successfully decompressed gzip content");
                match Channel::read_from(&decompressed[..]) {
                    Ok(channel) => {
                        log::info!("ğŸ‰ è§£å‹åè§£ææˆåŠŸ");
                        return Ok(self.parse_items_to_articles(&channel));
                    }
                    Err(e) => {
                        log::error!("Failed to parse decompressed RSS content: {:?}", e);
                    }
                }
            } else {
                log::error!("è§£å‹å¤±è´¥");
            }
        }

        // åœ¨æ‰€æœ‰RSSè§£æå°è¯•å¤±è´¥åï¼Œå°è¯•æ£€æµ‹å¹¶è§£æAtomæ ¼å¼
        log::info!("å°è¯•æ£€æµ‹Atomæ ¼å¼å¹¶è§£æ");
        // å°†bodyè½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥æ£€æµ‹Atomæ ¼å¼
        let text = String::from_utf8_lossy(&body).to_string();
        // æ£€æŸ¥æ˜¯å¦æ˜¯Atomæ ¼å¼
        if self.is_atom_format(&text) {
            log::info!("æ£€æµ‹åˆ°Atomæ ¼å¼ï¼Œå°è¯•ä½¿ç”¨Atomè§£æå™¨");
            // ä½¿ç”¨Atomè§£æå™¨è§£æ
            match self.parse_atom_content(&text, url) {
                Ok(articles) => {
                    log::info!("ğŸ‰ Atomè§£ææˆåŠŸ");
                    return Ok(articles);
                }
                Err(e) => {
                    log::error!("Atomè§£æå¤±è´¥: {:?}", e);
                }
            }
        }

        // å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œåˆ™è¿”å›é”™è¯¯
        Err(RssError::NetworkError(
            "æ— æ³•è§£æRSS/Atomå†…å®¹ï¼Œå°è¯•äº†å¤šç§ç¼–ç å’Œè§£ææ–¹æ³•".to_string(),
        ))
    }

    async fn get_from_cache(&self, url: &str) -> Option<Vec<Article>> {
        let mut cache = self.cache.lock().await;

        if let Some((timestamp, articles)) = cache.get(url) {
            if Instant::now().duration_since(*timestamp).as_secs() < self.cache_ttl {
                return Some(articles.clone());
            } else {
                // è¿‡æœŸäº†ï¼Œç§»é™¤ç¼“å­˜
                cache.remove(url);
            }
        }

        None
    }

    async fn add_to_cache(&self, url: &str, articles: Vec<Article>) {
        let mut cache = self.cache.lock().await;
        cache.insert(url.to_string(), (Instant::now(), articles));

        // é™åˆ¶ç¼“å­˜å¤§å°ï¼Œç§»é™¤æœ€æ—©çš„æ¡ç›®
        const MAX_CACHE_SIZE: usize = 100;
        if cache.len() > MAX_CACHE_SIZE {
            let oldest_key = cache
                .iter()
                .min_by_key(|(_, (ts, _))| ts)
                .map(|(key, _)| key.clone());

            if let Some(key) = oldest_key {
                cache.remove(&key);
            }
        }
    }

    /// ä½¿ç”¨Headless Chromeè·å–RSSæº
    async fn fetch_feed_with_headless_chrome(&self, url: &str) -> Result<Vec<Article>, RssError> {
        log::info!("å°è¯•ä½¿ç”¨Headless Chromeè·å–RSSæº: {}", url);
        
        // æ„å»ºæµè§ˆå™¨å¯åŠ¨é€‰é¡¹ï¼Œä½¿ç”¨éæ— å¤´æ¨¡å¼ä»¥é¿å…403é”™è¯¯
        // å¹¶æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼Œå°½é‡éšè—æµè§ˆå™¨çª—å£
        let launch_options = LaunchOptionsBuilder::default()
            .headless(false) // ç¦ç”¨æ— å¤´æ¨¡å¼ï¼Œå› ä¸ºå¾ˆå¤šç½‘ç«™ä¼šé˜»æ­¢æ— å¤´æµè§ˆå™¨
            .window_size(Some((800, 600)))
            // æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼Œå°†çª—å£å®šä½åˆ°å±å¹•å¤–
            .args(vec![
                OsStr::new("--window-position=-32000,-32000"), // å°†çª—å£å®šä½åˆ°å±å¹•å¤–
                OsStr::new("--no-startup-window"), // ä¸æ˜¾ç¤ºå¯åŠ¨çª—å£
                OsStr::new("--silent-launch"), // é™é»˜å¯åŠ¨
                OsStr::new("--disable-extensions"), // ç¦ç”¨æ‰©å±•
                OsStr::new("--disable-popup-blocking"), // ç¦ç”¨å¼¹çª—é˜»æ­¢
                OsStr::new("--disable-default-apps"), // ç¦ç”¨é»˜è®¤åº”ç”¨
            ])
            .build()
            .map_err(|e| {
                log::error!("æ„å»ºæµè§ˆå™¨å¯åŠ¨é€‰é¡¹å¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("Headless Chromeå¯åŠ¨å¤±è´¥: {:?}", e))
            })?;

        // å¯åŠ¨æµè§ˆå™¨
        let browser = Browser::new(launch_options)
            .map_err(|e| {
                log::error!("å¯åŠ¨Headless Chromeå¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("Headless Chromeå¯åŠ¨å¤±è´¥: {:?}", e))
            })?;

        // åˆ›å»ºæ–°æ ‡ç­¾é¡µ
        let tab = browser.new_tab()
            .map_err(|e| {
                log::error!("åˆ›å»ºæ–°æ ‡ç­¾é¡µå¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("åˆ›å»ºæ ‡ç­¾é¡µå¤±è´¥: {:?}", e))
            })?;
            

        // å¯¼èˆªåˆ°RSSæºURL
        tab.navigate_to(url)
            .map_err(|e| {
                log::error!("å¯¼èˆªåˆ°URLå¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("å¯¼èˆªå¤±è´¥: {:?}", e))
            })?;

        // ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
        tab.wait_until_navigated()
            .map_err(|e| {
                log::error!("ç­‰å¾…é¡µé¢åŠ è½½å¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("é¡µé¢åŠ è½½å¤±è´¥: {:?}", e))
            })?;

        // è·å–é¡µé¢å†…å®¹
        let page_content = tab.get_content()
            .map_err(|e| {
                log::error!("è·å–é¡µé¢å†…å®¹å¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("è·å–é¡µé¢å†…å®¹å¤±è´¥: {:?}", e))
            })?;

        log::info!("ä½¿ç”¨Headless Chromeè·å–åˆ°é¡µé¢å†…å®¹ï¼Œé•¿åº¦: {} bytes", page_content.len());
        log::info!("å†…å®¹é¢„è§ˆ: {:?}", &page_content[..std::cmp::min(page_content.len(), 200)]);

        // å°è¯•ä»HTMLä¸­æå–RSSå†…å®¹
        let rss_content = if page_content.starts_with("<?xml") {
            // å¦‚æœç›´æ¥æ˜¯XMLå†…å®¹ï¼Œç›´æ¥ä½¿ç”¨
            page_content
        } else {
            // å¦åˆ™å°è¯•ä»HTMLä¸­æå–RSSå†…å®¹
            log::info!("ä»HTMLé¡µé¢ä¸­æå–RSSå†…å®¹");
            
            // æŸ¥æ‰¾preæ ‡ç­¾ä¸­çš„å†…å®¹ï¼Œè¿™é€šå¸¸åŒ…å«RSS XML
            let pre_content = if let Some(start) = page_content.find("<pre") {
                if let Some(end_start) = page_content[start..].find(">").map(|i| start + i + 1) {
                    if let Some(end) = page_content[end_start..].find("</pre>").map(|i| end_start + i) {
                        page_content[end_start..end].to_string()
                    } else {
                        log::error!("æœªæ‰¾åˆ°</pre>æ ‡ç­¾");
                        return Err(RssError::NetworkError("ä»HTMLä¸­æå–RSSå†…å®¹å¤±è´¥: æœªæ‰¾åˆ°å®Œæ•´çš„preæ ‡ç­¾".to_string()));
                    }
                } else {
                    log::error!("æœªæ‰¾åˆ°<pre>æ ‡ç­¾çš„ç»“æŸç¬¦");
                    return Err(RssError::NetworkError("ä»HTMLä¸­æå–RSSå†…å®¹å¤±è´¥: æœªæ‰¾åˆ°preæ ‡ç­¾ç»“æŸç¬¦".to_string()));
                }
            } else {
                log::error!("æœªæ‰¾åˆ°<pre>æ ‡ç­¾");
                return Err(RssError::NetworkError("ä»HTMLä¸­æå–RSSå†…å®¹å¤±è´¥: æœªæ‰¾åˆ°preæ ‡ç­¾".to_string()));
            };
            
            log::info!("æå–åˆ°preæ ‡ç­¾å†…å®¹ï¼Œé•¿åº¦: {} bytes", pre_content.len());
            log::info!("preå†…å®¹é¢„è§ˆ: {:?}", &pre_content[..std::cmp::min(pre_content.len(), 200)]);
            
            // è§£ç HTMLå®ä½“ï¼Œå¦‚&lt; -> <
            let decoded_content = html_escape::decode_html_entities(&pre_content).to_string();
            log::info!("è§£ç åå†…å®¹é¢„è§ˆ: {:?}", &decoded_content[..std::cmp::min(decoded_content.len(), 200)]);
            
            decoded_content
        };

        // è§£æRSSå†…å®¹
        let channel = Channel::read_from(rss_content.as_bytes())
            .map_err(|e| {
                log::error!("è§£æRSSå†…å®¹å¤±è´¥: {:?}", e);
                RssError::ParseError(e)
            })?;

        // è½¬æ¢ä¸ºArticleç±»å‹
        Ok(self.parse_items_to_articles(&channel))
    }

    #[allow(unused)]
    pub async fn fetch_multiple_feeds(
        &self,
        urls: &[&str],
    ) -> HashMap<String, Result<Vec<Article>, RssError>> {
        let mut results = HashMap::new();
        let mut tasks = Vec::new();

        for &url in urls {
            let fetcher = self.clone();
            let url_str = url.to_string();

            // ç›´æ¥ä½¿ç”¨url_strï¼Œæ— éœ€é¢å¤–clone
            let task = tokio::spawn(async move { (url_str.clone(), fetcher.fetch_feed(&url_str).await) });

            tasks.push(task);
        }

        for task in tasks {
            if let Ok((url, result)) = task.await {
                results.insert(url, result);
            }
        }

        results
    }
    
    /// ä½¿ç”¨Headless Chromeè·å–ç½‘é¡µå†…å®¹
    pub async fn fetch_web_content(&self, url: &str) -> Result<String, RssError> {
        log::info!("å°è¯•ä½¿ç”¨Headless Chromeè·å–ç½‘é¡µå†…å®¹: {}", url);
        
        // æ„å»ºæµè§ˆå™¨å¯åŠ¨é€‰é¡¹ï¼Œä½¿ç”¨éæ— å¤´æ¨¡å¼ä»¥é¿å…403é”™è¯¯
        // å¹¶æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼Œå°½é‡éšè—æµè§ˆå™¨çª—å£
        let launch_options = LaunchOptionsBuilder::default()
            .headless(false) // ç¦ç”¨æ— å¤´æ¨¡å¼ï¼Œå› ä¸ºå¾ˆå¤šç½‘ç«™ä¼šé˜»æ­¢æ— å¤´æµè§ˆå™¨
            .window_size(Some((800, 600)))
            // æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼Œå°†çª—å£å®šä½åˆ°å±å¹•å¤–
            .args(vec![
                OsStr::new("--window-position=-32000,-32000"), // å°†çª—å£å®šä½åˆ°å±å¹•å¤–
                OsStr::new("--no-startup-window"), // ä¸æ˜¾ç¤ºå¯åŠ¨çª—å£
                OsStr::new("--silent-launch"), // é™é»˜å¯åŠ¨
                OsStr::new("--disable-extensions"), // ç¦ç”¨æ‰©å±•
                OsStr::new("--disable-popup-blocking"), // ç¦ç”¨å¼¹çª—é˜»æ­¢
                OsStr::new("--disable-default-apps"), // ç¦ç”¨é»˜è®¤åº”ç”¨
            ])
            .build()
            .map_err(|e| {
                log::error!("æ„å»ºæµè§ˆå™¨å¯åŠ¨é€‰é¡¹å¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("Headless Chromeå¯åŠ¨å¤±è´¥: {:?}", e))
            })?;

        // å¯åŠ¨æµè§ˆå™¨
        let browser = Browser::new(launch_options)
            .map_err(|e| {
                log::error!("å¯åŠ¨Headless Chromeå¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("Headless Chromeå¯åŠ¨å¤±è´¥: {:?}", e))
            })?;

        // åˆ›å»ºæ–°æ ‡ç­¾é¡µ
        let tab = browser.new_tab()
            .map_err(|e| {
                log::error!("åˆ›å»ºæ–°æ ‡ç­¾é¡µå¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("åˆ›å»ºæ ‡ç­¾é¡µå¤±è´¥: {:?}", e))
            })?;
            

        // å¯¼èˆªåˆ°URL
        tab.navigate_to(url)
            .map_err(|e| {
                log::error!("å¯¼èˆªåˆ°URLå¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("å¯¼èˆªå¤±è´¥: {:?}", e))
            })?;

        // ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
        tab.wait_until_navigated()
            .map_err(|e| {
                log::error!("ç­‰å¾…é¡µé¢åŠ è½½å¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("é¡µé¢åŠ è½½å¤±è´¥: {:?}", e))
            })?;

        // è·å–é¡µé¢å†…å®¹
        let page_content = tab.get_content()
            .map_err(|e| {
                log::error!("è·å–é¡µé¢å†…å®¹å¤±è´¥: {:?}", e);
                RssError::NetworkError(format!("è·å–é¡µé¢å†…å®¹å¤±è´¥: {:?}", e))
            })?;

        log::info!("ä½¿ç”¨Headless Chromeè·å–åˆ°ç½‘é¡µå†…å®¹ï¼Œé•¿åº¦: {} bytes", page_content.len());
        log::info!("å†…å®¹é¢„è§ˆ: {:?}", &page_content[..std::cmp::min(page_content.len(), 200)]);
        
        Ok(page_content)
    }

    /// å°†RSS Itemè½¬æ¢ä¸ºArticleç±»å‹
    fn parse_items_to_articles(&self, channel: &Channel) -> Vec<Article> {
        let source = channel.title().to_string();

        channel
            .items()
            .iter()
            .map(|item| self.item_to_article(item, &source))
            .collect()
    }

    /// å°†å•ä¸ªRSS Itemè½¬æ¢ä¸ºArticle
    fn item_to_article(&self, item: &Item, source: &str) -> Article {
        let pub_date = if let Some(date_str) = item.pub_date() {
            match self.parse_pub_date(date_str) {
                Ok(date) => date,
                Err(_) => {
                    log::warn!("Failed to parse date: {}", date_str);
                    Utc::now()
                }
            }
        } else {
            Utc::now()
        };

        let content = self.get_content(item);

        let summary = self.get_summary(item);

        // è·å–ä½œè€…ä¿¡æ¯ï¼Œé¦–å…ˆå°è¯•æ ‡å‡†authorå­—æ®µï¼Œç„¶åå°è¯•dc:creatoræ‰©å±•
        let author = item.author()
            .map(|a| a.to_string())
            .or_else(|| {
                // ä»Dublin Coreæ‰©å±•ä¸­è·å–dc:creatorä¿¡æ¯
                item.dublin_core_ext()
                    .and_then(|dc_ext| {
                        dc_ext.creators()
                            .first()
                            .map(|c| c.to_string())
                    })
            })
            .unwrap_or_else(|| "Unknown".to_string());

        Article {
            id: 0,      // å°†ç”±æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆ
            feed_id: 0, // å°†åœ¨æ·»åŠ åˆ°æ•°æ®åº“æ—¶è®¾ç½®
            title: html_escape::decode_html_entities(item.title().unwrap_or("Untitled")).to_string(),
            link: item.link().unwrap_or("").to_string(),
            author,
            pub_date,
            content,
            summary,
            is_read: false,
            is_starred: false,
            source: source.to_string(),
            guid: item.guid().map_or_else(
                || item.link().unwrap_or("").to_string(),
                |guid| guid.value().to_string(),
            ),
        }
    }

    /// è§£æå‘å¸ƒæ—¥æœŸ
    fn parse_pub_date(&self, date_str: &str) -> Result<DateTime<Utc>, chrono::ParseError> {
        // å°è¯•æ¸…ç†æ—¥æœŸå­—ç¬¦ä¸²ï¼Œç§»é™¤å¯èƒ½çš„å¤šä½™ç©ºæ ¼
        let trimmed_date_str = date_str.trim();

        // å°è¯•å¤šç§æ—¥æœŸæ ¼å¼ï¼Œç‰¹åˆ«æ·»åŠ GMTæ—¶åŒºæ ¼å¼å’Œæ›´å¤šå˜ä½“
        let formats = [
            "%a, %d %b %Y %H:%M:%S %z",
            "%a, %d %b %Y %H:%M:%S GMT", // ITä¹‹å®¶ä½¿ç”¨çš„æ ¼å¼
            "%a,%d %b %Y %H:%M:%S GMT",  // æ— ç©ºæ ¼å˜ä½“
            "%a, %d %b %Y %H:%M:%S %Z",  // å¸¦æ—¶åŒºåç§°çš„æ ¼å¼
            "%Y-%m-%dT%H:%M:%S%z",
            "%Y-%m-%d %H:%M:%S",
            "%d %b %Y %H:%M:%S",
            // RFC 2822 æ ¼å¼å˜ä½“
            "%a, %d %b %Y %H:%M:%S GMT+00:00",
            "%a, %d %b %Y %H:%M:%S +0000",
            // æ›´å¤šGMTæ ¼å¼å˜ä½“
            "%a, %d %b %Y %H:%M:%S GMT", // å¸¦é€—å·çš„GMTæ ¼å¼
            "%a, %d %b %Y %H:%M:%S %Z",  // å¸¦é€—å·çš„æ—¶åŒºåç§°æ ¼å¼
        ];

        // å°è¯•æ¯ç§æ ¼å¼ï¼Œè¿”å›ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœ
        for fmt in &formats {
            if let Ok(date) = DateTime::parse_from_str(trimmed_date_str, fmt) {
                return Ok(date.with_timezone(&Utc));
            }
        }

        // å°è¯•ä½¿ç”¨RFC 3339æ ¼å¼
        if let Ok(date) = DateTime::parse_from_rfc3339(trimmed_date_str) {
            return Ok(date.with_timezone(&Utc));
        }

        // å°è¯•è§£ææ²¡æœ‰é€—å·çš„GMTæ ¼å¼
        if trimmed_date_str.contains("GMT") && !trimmed_date_str.contains(",")
            && let Ok(date) = DateTime::parse_from_str(trimmed_date_str, "%a %d %b %Y %H:%M:%S GMT")
            {
                return Ok(date.with_timezone(&Utc));
            }

        // ä¸“é—¨å¤„ç†åŒ…å«é€—å·çš„GMTæ ¼å¼ï¼Œå°†GMTæ›¿æ¢ä¸º+00:00å†å°è¯•è§£æ
        if trimmed_date_str.contains(",") && trimmed_date_str.contains("GMT") {
            let modified_date_str = trimmed_date_str.replace("GMT", "+00:00");
            if let Ok(date) =
                DateTime::parse_from_str(&modified_date_str, "%a, %d %b %Y %H:%M:%S %z")
            {
                return Ok(date.with_timezone(&Utc));
            }
        }

        // æ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªé”™è¯¯
        // ç”±äºchrono::ParseErrorä¸æ”¯æŒç›´æ¥åˆ›å»ºï¼Œæˆ‘ä»¬å°è¯•è§£æä¸€ä¸ªæ— æ•ˆå­—ç¬¦ä¸²æ¥è·å–é”™è¯¯
        DateTime::parse_from_str("invalid-date", "%Y-%m-%d").map(|date| date.with_timezone(&Utc))
    }

    /// è·å–æ–‡ç« å†…å®¹
    fn get_content(&self, item: &Item) -> String {
        // é¦–å…ˆå°è¯•è·å–content:encoded
        if let Some(content) = item.content() {
            return self.sanitize_content(content);
        }

        // å¦‚æœæ²¡æœ‰ï¼Œå°è¯•è·å–description
        if let Some(description) = item.description() {
            return self.sanitize_content(description);
        }

        // å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        String::new()
    }

    /// è·å–æ–‡ç« æ‘˜è¦
    fn get_summary(&self, item: &Item) -> String {
        // é¦–å…ˆå°è¯•è·å–description
        if let Some(description) = item.description() {
            let plain_text = self.html_to_plain_text(description);
            return plain_text.chars().take(200).collect::<String>();
        }

        if let Some(content) = item.content() {
            let plain_text = self.html_to_plain_text(content);
            return plain_text.chars().take(200).collect::<String>();
        }

        // å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        String::new()
    }

    /// æ¸…ç†HTMLå†…å®¹ï¼Œç§»é™¤æ— ç”¨æ ‡ç­¾ï¼Œåªä¿ç•™çº¯æ–‡æœ¬å’Œå¿…è¦æ ¼å¼
    fn sanitize_content(&self, html: &str) -> String {
        // é¦–å…ˆä½¿ç”¨html2textå°†HTMLè½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼Œä¿ç•™åŸºæœ¬æ ¼å¼
        let plain_text = self.html_to_plain_text(html);
        
        // è§£ç HTMLå®ä½“
        let decoded = html_escape::decode_html_entities(&plain_text);
        
        // ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦ï¼Œä¿ç•™åˆç†çš„æ¢è¡Œå’Œç©ºæ ¼
        
        
        decoded
            .lines()
            .map(|line| line.trim())
            .filter(|line| !line.is_empty())
            .collect::<Vec<_>>()
            .join("\n")
    }

    /// æå–æ–‡ç« ä¸­çš„å›¾ç‰‡
    #[allow(unused)]
    pub fn extract_images(&self, html: &str) -> Vec<String> {
        let mut images = Vec::new();

        // ç» â‚¬é—æ› æ®‘é¥å‰§å¢–é»æ„¬å½‡é–«æ˜ç·«
        for part in html.split("<img") {
            if let Some(start) = part.find("src=") {
                let src_part = &part[start + 5..];
                if let Some(end) = src_part.find('"') {
                    images.push(src_part[..end].to_string());
                }
            }
        }

        images
    }

    /// è·å–è®¢é˜…æºå›¾æ ‡URL
    #[allow(unused)]
    pub async fn get_favicon_url(&self, feed_url: &str) -> Option<String> {
        // å°è¯•ä»åŸŸåè·å–favicon
        if let Some(domain) = self.extract_domain(feed_url) {
            let favicon_url = format!("https://{}/favicon.ico", domain);

            // æ£€æµ‹faviconæ˜¯å¦å­˜åœ¨
            if let Ok(response) = self.client.head(&favicon_url).send().await
                && response.status().is_success() {
                    return Some(favicon_url);
                }
        }

        None
    }

    /// ä»URLæå–åŸŸå
    #[allow(unused)]
    fn extract_domain(&self, url: &str) -> Option<String> {
        // ç®€å•çš„åŸŸåæå–é€»è¾‘
        if let Some(start) = url.find("://") {
            let remaining = &url[start + 3..];
            if let Some(end) = remaining.find('/') {
                return Some(remaining[..end].to_string());
            } else {
                return Some(remaining.to_string());
            }
        }

        None
    }

    /// å°è¯•æ‰‹åŠ¨è§£å‹gzipå†…å®¹ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆï¼Œæ›´åŠ çµæ´»åœ°å¤„ç†å„ç§å‹ç¼©æ ¼å¼
    fn try_decompress_gzip(&self, bytes: &[u8]) -> Result<Vec<u8>, std::io::Error> {
        use std::io::Read;

        // å³ä½¿æ²¡æœ‰æ ‡å‡†gzipå¤´éƒ¨ä¹Ÿå°è¯•è§£å‹ï¼Œå› ä¸ºITä¹‹å®¶RSSæºå¯èƒ½ä½¿ç”¨éæ ‡å‡†å‹ç¼©
        log::info!("Attempting to manually decompress content, even without standard gzip header");

        // æ£€æŸ¥æ˜¯å¦æœ‰gzipå¤´éƒ¨æ ‡è¯†ï¼ˆ1F 8Bï¼‰
        if bytes.len() >= 2 && bytes[0] == 0x1F && bytes[1] == 0x8B {
            log::debug!("æ£€æµ‹åˆ°æ ‡å‡†gzipå¤´éƒ¨ï¼Œå°è¯•æ ‡å‡†è§£å‹");

            // å°è¯•gzipè§£å‹
            let mut decoder = GzDecoder::new(bytes);
            let mut decompressed = Vec::new();
            match decoder.read_to_end(&mut decompressed) {
                Ok(_) => {
                    log::debug!(
                        "Successfully decompressed with gzip decoder, size: {} bytes",
                        decompressed.len()
                    );
                    return Ok(decompressed);
                }
                Err(e) => {
                    log::warn!("Gzip decompression failed: {}, trying fallback methods", e);
                }
            }
        }

        // å°è¯•ä½¿ç”¨flate2çš„ä½çº§åˆ«API
        let mut decoder = flate2::read::MultiGzDecoder::new(bytes);
        let mut decompressed = Vec::new();
        match decoder.read_to_end(&mut decompressed) {
            Ok(_) => {
                log::debug!(
                    "Successfully decompressed with MultiGzDecoder, size: {} bytes",
                    decompressed.len()
                );
                return Ok(decompressed);
            }
            Err(e) => {
                log::warn!("MultiGzDecoder decompression failed: {}", e);
            }
        }

        // å°è¯•ä½¿ç”¨deflateè§£ç å™¨
        log::info!("å°è¯•ä½¿ç”¨deflateè§£ç å™¨");
        let mut decoder = flate2::read::DeflateDecoder::new(bytes);
        let mut decompressed = Vec::new();
        match decoder.read_to_end(&mut decompressed) {
            Ok(_) => {
                log::debug!(
                    "Successfully decompressed with DeflateDecoder, size: {} bytes",
                    decompressed.len()
                );
                return Ok(decompressed);
            }
            Err(e) => {
                log::warn!("DeflateDecoder decompression failed: {}", e);
            }
        }

        // æ‰€æœ‰è§£å‹æ–¹æ³•éƒ½å¤±è´¥
        Err(std::io::Error::new(
            std::io::ErrorKind::InvalidData,
            "Failed to decompress data with all available methods",
        ))
    }

    /// å°è¯•ä»HTMLé¡µé¢ä¸­æå–RSSé“¾æ¥
    fn extract_rss_link_from_html(&self, html: &str) -> Option<String> {
        // æŸ¥æ‰¾ç±»ä¼¼ <link rel="alternate" type="application/rss+xml" href="..."> çš„æ ‡ç­¾
        if let Ok(pattern) = regex::Regex::new(
            r#"<link[^>]+rel=['"]alternate['"].*?type=['"]application/rss\+xml['"].*?href=['"]([^'"]+)['"]"#,
        )
            && let Some(caps) = pattern.captures(html) {
                return Some(caps[1].to_string());
            }

        // æŸ¥æ‰¾ç±»ä¼¼ <link rel="alternate" type="application/atom+xml" href="..."> çš„æ ‡ç­¾
        if let Ok(pattern) = regex::Regex::new(
            r#"<link[^>]+rel=['"]alternate['"].*?type=['"]application/atom\+xml['"].*?href=['"]([^'"]+)['"]"#,
        )
            && let Some(caps) = pattern.captures(html) {
                return Some(caps[1].to_string());
            }

        None
    }

    /// å°è¯•å°†å­—èŠ‚æ•°ç»„è§£ç ä¸ºUTF-16
    fn try_decode_utf16(&self, bytes: &[u8]) -> Vec<u16> {
        let mut result = Vec::new();

        // æ£€æŸ¥æ˜¯å¦æœ‰BOM
        let is_be = bytes.len() >= 2 && bytes[0] == 0xFE && bytes[1] == 0xFF;

        // è·³è¿‡BOM
        let start_idx = if bytes.len() >= 2
            && (bytes[0] == 0xFE && bytes[1] == 0xFF || bytes[0] == 0xFF && bytes[1] == 0xFE)
        {
            2
        } else {
            0
        };

        // è§£ç å‰©ä½™çš„å­—èŠ‚
        let mut i = start_idx;
        while i + 1 < bytes.len() {
            let value = if is_be {
                ((bytes[i] as u16) << 8) | (bytes[i + 1] as u16)
            } else {
                ((bytes[i + 1] as u16) << 8) | (bytes[i] as u16)
            };
            result.push(value);
            i += 2;
        }

        result
    }

    /// æå–é“¾æ¥URLï¼Œç¡®ä¿æ˜¯æœ‰æ•ˆçš„URLæ ¼å¼
    #[allow(unused)]
    pub fn extract_link_url(&self, url: &str, base_url: &Option<String>) -> String {
        // å¦‚æœURLå·²ç»æ˜¯å®Œæ•´çš„ï¼Œåˆ™ç›´æ¥è¿”å›
        if let Ok(parsed) = Url::parse(url)
            && parsed.scheme() != "" && parsed.domain().is_some() {
                return url.to_string();
            }

        // å¦‚æœæœ‰åŸºç¡€URLï¼Œå°è¯•æ„å»ºå®Œæ•´URL
        if let Some(base) = base_url
            && let Ok(base_parsed) = Url::parse(base)
                && let Ok(joined) = base_parsed.join(url) {
                    return joined.to_string();
                }

        // æ— æ³•æ„å»ºæœ‰æ•ˆURLï¼Œè¿”å›åŸå§‹å€¼
        url.to_string()
    }

    /// å°†HTMLè½¬æ¢ä¸ºçº¯æ–‡æœ¬
    fn html_to_plain_text(&self, html: &str) -> String {
        let cursor = Cursor::new(html);
        // å¤„ç†from_readå¯èƒ½è¿”å›çš„é”™è¯¯ï¼Œå¦‚æœå‡ºé”™åˆ™è¿”å›åŸå§‹HTMLå­—ç¬¦ä¸²
        match from_read(cursor, 80) {
            Ok(plain_text) => plain_text,
            Err(_) => html.to_string(), // å‡ºé”™æ—¶è¿”å›åŸå§‹HTML
        }
    }

    /// ä»OPMLå­—ç¬¦ä¸²å¯¼å…¥è®¢é˜…æº
    #[allow(unused)]
    pub async fn import_from_string(
        &self,
        opml_content: &str,
    ) -> Result<Vec<(String, String, String)>, anyhow::Error> {
        let document = roxmltree::Document::parse(opml_content)?;

        let mut feeds = Vec::new();

        // å¯»æ‰¾æ‰€æœ‰outlineå…ƒç´ 
        for outline in document
            .descendants()
            .filter(|n| n.tag_name().name() == "outline")
        {
            if let Some(type_attr) = outline.attribute("type") {
                if (type_attr == "rss" || type_attr == "atom")
                    && let (Some(title), Some(url)) = (
                        outline.attribute("title").or(outline.attribute("text")),
                        outline.attribute("xmlUrl"),
                    ) {
                        // è·å–å±‚çº§åˆ†ç»„åç§°
                        let group = if let Some(parent) = outline.parent() {
                            if parent.tag_name().name() == "outline" {
                                parent
                                    .attribute("title")
                                    .or(parent.attribute("text"))
                                    .unwrap_or("")
                                    .to_string()
                            } else {
                                String::new()
                            }
                        } else {
                            String::new()
                        };

                        feeds.push((title.to_string(), url.to_string(), group));
                    }
            } else if outline.attribute("xmlUrl").is_some()
                && let (Some(title), Some(url)) = (
                    outline.attribute("title").or(outline.attribute("text")),
                    outline.attribute("xmlUrl"),
                ) {
                    // é‘¾å³°å½‡é–å‰éª‡é’å—™ç²éšå¶‡Ğ
                    let group = if let Some(parent) = outline.parent() {
                        if parent.tag_name().name() == "outline" {
                            parent
                                .attribute("title")
                                .or(parent.attribute("text"))
                                .unwrap_or("")
                                .to_string()
                        } else {
                            String::new()
                        }
                    } else {
                        String::new()
                    };

                    feeds.push((title.to_string(), url.to_string(), group));
                }
        }

        Ok(feeds)
    }

    // æ³¨æ„ï¼šimport_and_validateæ–¹æ³•åº”è¯¥åœ¨OpmlHandlerä¸­

    /// ç”ŸæˆOPMLå†…å®¹
    #[allow(unused)]
    pub async fn generate_opml(&self, feeds: &[(String, String, String)]) -> String {
        let mut opml = String::new();

        // å†™å…¥OPMLå¤´éƒ¨
        opml.push_str("<?xml version=\"1.0\" encoding=\"UTF-8\"?><opml version=\"1.0\">");
        opml.push_str("<head>");
        opml.push_str("<title>Rust RSS Reader Subscriptions</title>");
        opml.push_str("<dateCreated>");
        opml.push_str(&Utc::now().to_rfc3339().to_string());
        opml.push_str("</dateCreated>");
        opml.push_str("<ownerName>Rust RSS Reader</ownerName>");
        opml.push_str("</head>");
        opml.push_str("<body>");

        // æŒ‰åˆ†ç»„ç»„ç»‡è®¢é˜…æº
        let mut groups = std::collections::HashMap::new();
        for (title, url, group) in feeds {
            groups
                .entry(group.clone())
                .or_insert_with(Vec::new)
                .push((title, url));
        }

        if let Some(no_group_feeds) = groups.get("") {
            for (title, url) in no_group_feeds {
                opml.push_str(&format!(
                    "<outline type=\"rss\" title=\"{}\" text=\"{}\" xmlUrl=\"{}\"/>",
                    html_escape::encode_text(title),
                    html_escape::encode_text(title),
                    html_escape::encode_text(url)
                ));
            }
        }

        for (group_name, feeds) in groups {
            if !group_name.is_empty() {
                opml.push_str(&format!(
                    "<outline text=\"{}\" title=\"{}\">\n",
                    html_escape::encode_text(&group_name),
                    html_escape::encode_text(&group_name)
                ));

                for (title, url) in feeds {
                    opml.push_str(&format!(
                        "  <outline type=\"rss\" title=\"{}\" text=\"{}\" xmlUrl=\"{}\"/>",
                        html_escape::encode_text(title),
                        html_escape::encode_text(title),
                        html_escape::encode_text(url)
                    ));
                }

                opml.push_str("</outline>");
            }
        }

        // å†™å…¥OPMLå°¾éƒ¨
        opml.push_str("</body></opml>");

        opml
    }

    /// ä»OPMLæ–‡ä»¶å¯¼å…¥è®¢é˜…æº
    #[allow(unused)]
    pub async fn import_from_file<P: AsRef<std::path::Path>>(
        &self,
        path: P,
    ) -> Result<Vec<(String, String, String)>, anyhow::Error> {
        let opml_content = tokio::fs::read_to_string(path).await?;
        let document = roxmltree::Document::parse(&opml_content)?;

        let mut feeds = Vec::new();

        // å¯»æ‰¾æ‰€æœ‰outlineå…ƒç´ 
        for outline in document
            .descendants()
            .filter(|n| n.tag_name().name() == "outline")
        {
            if let Some(type_attr) = outline.attribute("type")
                && (type_attr == "rss" || type_attr == "atom")
                && let (Some(title), Some(url)) = (
                    outline.attribute("title").or(outline.attribute("text")),
                    outline.attribute("xmlUrl"),
                ) {
                    // è·å–å±‚çº§åˆ†ç»„åç§°
                    let group = if let Some(parent) = outline.parent() {
                        parent
                            .attribute("title")
                            .or(parent.attribute("text"))
                            .unwrap_or("")
                            .to_string()
                    } else {
                        String::new()
                    };

                    feeds.push((title.to_string(), url.to_string(), group));
            }
        }

        Ok(feeds)
    }

    /// æ£€æµ‹å†…å®¹æ˜¯å¦ä¸ºAtomæ ¼å¼
    fn is_atom_format(&self, content: &str) -> bool {
        // æ£€æŸ¥æ˜¯å¦åŒ…å«Atomå‘½åç©ºé—´
        content.contains("xmlns=\"http://www.w3.org/2005/Atom\"") || 
        // æ£€æŸ¥æ˜¯å¦åŒ…å«Atomç‰¹æœ‰çš„å…ƒç´ 
        (content.contains("<feed") && content.contains("</feed>") && content.contains("<entry") && content.contains("</entry>"))
    }

    /// è§£æAtomæ ¼å¼çš„å†…å®¹ï¼Œæå–æ–‡ç« ä¿¡æ¯
    fn parse_atom_content(&self, content: &str, feed_url: &str) -> Result<Vec<Article>, RssError> {
        log::info!("å°è¯•è§£æAtomæ ¼å¼å†…å®¹");

        // ä½¿ç”¨roxmltreeè§£æXML/Atom
        let doc = match Document::parse(content) {
            Ok(doc) => doc,
            Err(e) => {
                log::error!("XMLè§£æé”™è¯¯: {}", e);
                return Err(RssError::XmlError(e.to_string()));
            }
        };

        let root = doc.root_element();
        let mut articles = Vec::new();

        // æŸ¥æ‰¾æ‰€æœ‰æ–‡ç« æ¡ç›®
        let entries: Vec<_> = root
            .descendants()
            .filter(|n| n.is_element() && n.tag_name().name() == "entry")
            .collect();

        log::info!("æ‰¾åˆ° {} ä¸ªæ–‡ç« æ¡ç›®", entries.len());

        // è§£ææ¯ä¸ªæ–‡ç« æ¡ç›®
        for entry in entries {
            // æå–æ ‡é¢˜
            let title = entry
                .descendants()
                .find(|n| n.is_element() && n.tag_name().name() == "title")
                .and_then(|n| n.text())
                .filter(|t| !t.trim().is_empty())
                .map(|t| html_escape::decode_html_entities(t.trim()).to_string())
                .unwrap_or_else(|| "[æ— æ ‡é¢˜]".to_string());

            // æå–é“¾æ¥
            let link = entry
                .descendants()
                .filter(|n| n.is_element() && n.tag_name().name() == "link")
                .find_map(|n| n.attribute("href"))
                .unwrap_or("")
                .to_string();

            // æå–å‘å¸ƒæ—¶é—´ï¼Œä¼˜å…ˆä½¿ç”¨publishedï¼Œç„¶åæ˜¯updated
            let pub_date = entry
                .descendants()
                .find(|n| n.is_element() && n.tag_name().name() == "published")
                .or_else(|| {
                    entry
                        .descendants()
                        .find(|n| n.is_element() && n.tag_name().name() == "updated")
                })
                .and_then(|n| n.text())
                .map(|text| match DateTime::parse_from_rfc3339(text.trim()) {
                    Ok(dt) => dt.with_timezone(&Utc),
                    Err(e) => {
                        log::warn!("è§£ææ—¥æœŸå¤±è´¥: {}, ä½¿ç”¨å½“å‰æ—¶é—´", e);
                        Utc::now()
                    }
                })
                .unwrap_or_else(Utc::now);

            // æå–æ‘˜è¦
            let summary = entry
                .descendants()
                .find(|n| n.is_element() && n.tag_name().name() == "summary")
                .and_then(|n| n.text())
                .map(|t| t.trim().to_string())
                .unwrap_or_else(String::new);

            // æå–å†…å®¹
            let content_str = entry
                .descendants()
                .find(|n| n.is_element() && n.tag_name().name() == "content")
                .and_then(|n| n.text())
                .map(|t| t.trim().to_string())
                .unwrap_or_else(|| summary.clone());
            
            // æ¸…ç†å†…å®¹ï¼Œç§»é™¤æ— ç”¨æ ‡ç­¾
            let cleaned_content = self.sanitize_content(&content_str);
            let cleaned_summary = if !summary.is_empty() && summary != content_str {
                self.html_to_plain_text(&summary).chars().take(200).collect::<String>()
            } else {
                String::new()
            };

            // æå–ä½œè€…
            let author = entry
                .descendants()
                .find(|n| n.is_element() && n.tag_name().name() == "author")
                .and_then(|author_elem| {
                    author_elem
                        .descendants()
                        .find(|n| n.is_element() && n.tag_name().name() == "name")
                        .and_then(|n| n.text())
                        .map(|t| t.trim().to_string())
                })
                .unwrap_or_else(String::new);

            // æå–GUIDæˆ–ä½¿ç”¨é“¾æ¥ä½œä¸ºGUID
            let guid = entry
                .descendants()
                .find(|n| n.is_element() && n.tag_name().name() == "id")
                .and_then(|n| n.text())
                .map(|t| t.trim().to_string())
                .unwrap_or_else(|| link.clone());

            // åˆ›å»ºæ–‡ç« å¯¹è±¡
            let article = Article {
                id: 0,      // å°†ç”±æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆ
                feed_id: 0, // å°†åœ¨æ·»åŠ åˆ°æ•°æ®åº“æ—¶è®¾ç½®
                title,
                link,
                author,
                pub_date,
                content: cleaned_content,
                summary: cleaned_summary,
                is_read: false,
                is_starred: false,
                source: feed_url.to_string(), // ä½¿ç”¨feed_urlä½œä¸ºsource
                guid,
            };

            articles.push(article);
        }

        if articles.is_empty() {
            log::warn!("Atomè§£ææˆåŠŸä½†æœªæ‰¾åˆ°ä»»ä½•æ–‡ç« ");
            return Err(RssError::AtomParseError);
        }

        log::info!("æˆåŠŸè§£æAtomæ ¼å¼ï¼Œå…±æ‰¾åˆ° {} ç¯‡æ–‡ç« ", articles.len());
        Ok(articles)
    }
}

impl Clone for RssFetcher {
    fn clone(&self) -> Self {
        Self {
            client: self.client.clone(),
            user_agent: self.user_agent.clone(),
            cache: self.cache.clone(),
            cache_ttl: self.cache_ttl,
        }
    }
}

/// OPMLå¯¼å…¥å¯¼å‡ºåŠŸèƒ½
pub struct OpmlHandler {
    fetcher: Option<RssFetcher>,
}

impl OpmlHandler {
    #[allow(unused)]
    pub fn new() -> Self {
        Self { fetcher: None }
    }

    /// éªŒè¯è®¢é˜…æºæ˜¯å¦æœ‰æ•ˆ
    #[allow(unused)]
    pub async fn validate_feeds(
        &self,
        feeds: &[(String, String, String)],
    ) -> Result<Vec<(String, String, String, bool)>, anyhow::Error> {
        if let Some(fetcher) = &self.fetcher {
            let mut validated_feeds = Vec::new();

            for (title, url, group) in feeds {
                // éªŒè¯URLæ˜¯å¦æœ‰æ•ˆ
                let is_valid = match fetcher.fetch_feed(url).await {
                    Ok(_) => true,
                    Err(e) => {
                        log::warn!("Invalid feed {} ({}): {:?}", title, url, e);
                        false
                    }
                };

                validated_feeds.push((title.clone(), url.clone(), group.clone(), is_valid));
            }

            Ok(validated_feeds)
        } else {
            Err(anyhow::anyhow!("Fetcher not initialized"))
        }
    }

    #[allow(unused)]
    pub fn with_fetcher(user_agent: String) -> Self {
        Self {
            fetcher: Some(RssFetcher::new(user_agent)),
        }
    }

    #[allow(unused)]
    pub fn set_fetcher(&mut self, user_agent: String) {
        self.fetcher = Some(RssFetcher::new(user_agent));
    }
    #[allow(unused)]
    pub async fn import_from_file<P: AsRef<std::path::Path>>(
        &self,
        path: P,
    ) -> Result<Vec<(String, String, String)>, anyhow::Error> {
        let opml_content = tokio::fs::read_to_string(path).await?;
        let document = roxmltree::Document::parse(&opml_content)?;

        let mut feeds = Vec::new();

        // éŒãƒ¦å£˜éµâ‚¬éˆå¡·utlineéå†ªç¤Œ
        for outline in document
            .descendants()
            .filter(|n| n.tag_name().name() == "outline")
        {
            if let Some(type_attr) = outline.attribute("type")
                && (type_attr == "rss" || type_attr == "atom")
                && let (Some(title), Some(url)) = (
                    outline.attribute("title").or(outline.attribute("text")),
                    outline.attribute("xmlUrl"),
                ) {
                    // é‘¾å³°å½‡é–å‰éª‡é’å—™ç²éšå¶‡Ğ
                    let group = if let Some(parent) = outline.parent() {
                        parent
                            .attribute("title")
                            .or(parent.attribute("text"))
                            .unwrap_or("")
                            .to_string()
                    } else {
                        String::new()
                    };

                    feeds.push((title.to_string(), url.to_string(), group));
            }
        }

        Ok(feeds)
    }

    /// å¯¼å‡ºè®¢é˜…æºä¸ºOPMLæ–‡ä»¶
    #[allow(unused)]
    pub async fn export_to_file<P: AsRef<std::path::Path>>(
        &self,
        path: P,
        feeds: &[(String, String, String)],
    ) -> Result<(), anyhow::Error> {
        let mut opml = String::new();

        // å†™å…¥OPMLå¤´éƒ¨
        opml.push_str("<?xml version=\"1.0\" encoding=\"UTF-8\"?><opml version=\"1.0\">");
        opml.push_str("<head><title>Rust RSS Reader Subscriptions</title></head>");
        opml.push_str("<body>");

        // æŒ‰åˆ†ç»„ç»„ç»‡è®¢é˜…æº
        let mut groups = std::collections::HashMap::new();
        for (title, url, group) in feeds {
            groups
                .entry(group.clone())
                .or_insert_with(Vec::new)
                .push((title, url));
        }

        if let Some(no_group_feeds) = groups.get("") {
            for (title, url) in no_group_feeds {
                opml.push_str(&format!(
                    "<outline type=\"rss\" title=\"{}\" xmlUrl=\"{}\"/>",
                    html_escape::encode_text(title),
                    html_escape::encode_text(url)
                ));
            }
        }

        for (group_name, feeds) in groups {
            if !group_name.is_empty() {
                opml.push_str(&format!(
                    "<outline text=\"{}\" title=\"{}\">\n",
                    html_escape::encode_text(&group_name),
                    html_escape::encode_text(&group_name)
                ));

                for (title, url) in feeds {
                    opml.push_str(&format!(
                        "  <outline type=\"rss\" title=\"{}\" xmlUrl=\"{}\"/>",
                        html_escape::encode_text(title),
                        html_escape::encode_text(url)
                    ));
                }

                opml.push_str("</outline>");
            }
        }

        // å†™å…¥OPMLå°¾éƒ¨
        opml.push_str("</body></opml>");

        // å†™å…¥æ–‡ä»¶
        tokio::fs::write(path, opml).await?;

        Ok(())
    }
}
